# 灰度系统



## 背景

为了保证线上业务质量，因此做了一套后台灰度系统。通过简易的配置即可将系统进行灰度。该系统已在线上生产环境正式运行2年时间。
基于Dubbo、Spring扩展实现。现把灰度系统的代码抽离出来。



## 使用场景

业务系统使用灰度系统之后，用户的请求过来了，会根据用户的身份态进行路由，如果是灰度用户，则将请求转发到灰度环境；如果是正式用户，则将请求转发到正式环境。



## 功能点

- 可以基于单个服务灰度（也可以整体控制灰度）
- 基于接口灰度
- 外部依赖接口的灰度
- mq灰度
- 接入层与服务之间的灰度调用
- 服务于服务之间的灰度调用
- 支持多套灰度环境
- 容灾：灰度/正式服务不可用，降级调用正式/灰度服务





## 系统架构

整体分为：灰度配置模块、后台管理模块、代理模块、灰度组件（核心）
![Snip20180920_1](http://ww2.sinaimg.cn/large/006y8mN6gy1g6ua2h29mdj30z20h075i.jpg)





## 使用方法

### 服务引入灰度配置
1、创建 META-INF.dubbo文件夹

2、配置filter 
 （1）创建 com.alibaba.dubbo.rpc.Filter文件
  内容是 grayFilter=com.facishare.wechat.union.common.component.DubboGrayFilter
  如果需要自定义filter，可以继承com.facishare.wechat.union.common.component.DubboGrayFilter，
  然后在等号后面写上实现类

3、配置loadBalance
 （1）创建 com.alibaba.dubbo.rpc.cluster.LoadBalance文件
  内容是 grayLoadBalance=com.facishare.xxx.xxx.xxxLoadBalance
  普通项目只要进行步骤（1）就可以了

 （2）在web、fcp项目中，需要创建子类xxxLoadBalance，并且把实现类路径写在等号后面，
  主要是获取fsEa

4、spring配置文件中添加
  `<import resource="classpath*:/spring/wechat-union-common.xml"/>`

PS：简单来说，除了web接入层的项目，其他项目只要
 （1）创建com.alibaba.dubbo.rpc.Filter、com.alibaba.dubbo.rpc.cluster.LoadBalance文件
 （2）导入`<import resource="classpath*:/spring/wechat-union-common.xml"/>`



### 机器准备

PS: 如果部署有问题，请致邮件：  296947440@qq.com  除了上班时间基本在线<br/><br/>
灰度机器2台（如果外部依赖的都是旧接口，1台就好了），正式机器1台
注意灰度系统是支持多套灰度环境的，一套灰度环境建议使用2台机器（容灾）<br/><br/>

灰度机器，需要部署2台。正常机器一台即可（之所以灰度机器需要两台以上，是因为只部署一台的话，那么新的接口service只有1个invoker，
因此不经过loadBalance，因此没有给group赋值，因此去provider侧寻找invoker的时候，会找不到）
<br/><br/>





### 后台管理灰度配置

#### 配置灰度环境
配置灰度环境之前，需要部署启动gray-config-admin项目<br/><br/>
![image-20190916163851104](http://ww1.sinaimg.cn/large/006y8mN6gy1g71g4yp6ryj319i0hs75i.jpg)
如图，配置了2个灰度环境，并且含有各自环境的灰度名单

#### 配置灰度应用
![image-20190916164009751](http://ww3.sinaimg.cn/large/006y8mN6gy1g71g6btj6dj319s08wq46.jpg)
把灰度服务配置到灰度环境中，一个灰度服务可以在多个灰度环境中，一个灰度服务的某台机器只能在1个灰度环境中。

#### 启动服务
配置好灰度配置后，就可以启动服务了，生成灰度环境了。剩下的就是动态路由调用。
<br/><br/><br/>



## 实现原理

### 划分灰度环境
在服务启动时，根据该服务的灰度机器列表，判断该服务下这个台机器是否需要灰度，如果是，则设置为灰度环境配置（该服务设置为灰度group）。
                   通过使用GrayBeanPostProcessor初始化之后，通过group的来划分，dubbo服务被划分灰度环境、正式环境。这里需要注意的是，该灰度系统的核心之一就是通过group进行灰度环境的划分。

具体流程如图：
![Snip20180920_1](http://ww4.sinaimg.cn/large/006y8mN6gy1g6tirria2mj31m60i6aem.jpg)
<br/><br/>

### 动态路由

PS：动态路由是我们自己写的一个java接入层来实现的

通过上面的步骤，已经将服务划分为灰度环境、正式环境。接下来就是利用dubbo的loadBalance、Filter扩展，达到动态调用灰度/正式服务的效果。调用的顺序为loadBalance——》filter。

具体要怎么做呢？
在consumer侧，我们为了在LoadBalance中获取到所有provder对应的invoker，所以设置group为“*”。然后我们根据首先根据请求的身份信息，判断该用户走灰度还是正式环境，然后调用灰度/正式服务。
在provider侧，所有invoker都被存储在map中，等待consumer进行获取调用，并且key的里面包含了group，所以consume进行调用的时候，必须要携带group，才能把group作为key的一部分，去正常的获取到invoker。

如果consumer调用的时候不携带group，那么dubbo默认会把ConsumerConfig的group属性值当做参数传递给provider方。而在在provider侧，会从一个Map获取接口的exporter，key类似于 */com.xxxx.xxService.queryMethod这种格式，因此，这样子是拿不到invoker的。

![Snip20180920_1](http://ww3.sinaimg.cn/large/006y8mN6gy1g6tiy57mkhj30vs07dmyr.jpg)
![Snip20180920_1](http://ww1.sinaimg.cn/large/006y8mN6gy1g6tiyy5xeuj31dr0opqf1.jpg)

另外，对于灰度服务的调用，我们会将“*”替换成灰度的group，这样子能正常调用成功。但是对于正常服务的调用，是没有group的，因此dubbo直接把group=“*“传递给provider，调用失败。

因此我们做了一个兼容性的错误，通过provider侧的filter去把非灰度group（也就是”*“）设置为空，那么非灰度服务也能正常调用了。

通过查看源代码，在provider侧获取exporter进行调用时，使用invocation获取group值，利用该值组成key，因此，如果在consumer消费之前，可以通过invocation设置group的值（调用灰度服务，则设置为对应的灰度group；调用正式服务，则设置为”“，因为”“不会被添加到key中），就可以获取得到exporter，从而达到调用灰度/正式服务的效果

![Snip20180920_5](http://ww4.sinaimg.cn/large/006y8mN6gy1g6tk21ugc2j30te0zon2x.jpg)
<br/><br/>






### 代理层实现外部调用灰度
说明：外部服务调用interface.method1的时候，调用proxy项目的interface.method1，然后获取用户信息（fsEa、wxAppId、appId...），
从而判断是走灰度服务，还是正常服务，选择完毕，调用project的同名服务
![Snip20180920_1](http://ww4.sinaimg.cn/large/006y8mN6gy1g6ubrnme3vj30t604rglu.jpg)

<br/><br/>





### mq灰度处理

根据topic进行灰度，灰度环境使用灰度topic，生产环境使用正式的topic。

<br/><br/>





## 价值

对比其他灰度系统，这个灰度系统在service层做了一层灰度（因为业务逻辑代码一般都写在service层）。无需太多硬件支持，只需要部署灰度的物理机器，不需要新的一套Zookeeper注册中心、Redis等。

- 节约成本
- 保证产品的平稳发布，逐步灰度用户
- 让用户能够使用到更加可靠的新产品





<br/><br/>

## 发展方向

支持按照百分比灰度。

比如说先灰度5%的用户，然后再灰度10%的用户，逐步扩大灰度比例，稳步发布产品。

<br/><br/>







## 扩展

com.alibaba.dubbo.common.utils.UrlUtils#isMatch 解释了*为何会匹配到所有invoker





## 灰度系统 2.0

之前灰度系统的核心是使用group来实现服务的灰度。但是有如下问题：

- 基于group来实现，那么灰度的提供者必须有2台以上的机器，对于测试环境，部署两台机器比较浪费资源
  - 灰度机器，需要部署2台。正常机器一台即可（之所以灰度机器需要两台以上，是因为只部署一台的话，那么新的接口只有1个提供者，因此不经过loadBalance，因此没有给group赋值灰度的group，因此去提供者侧的map中查找Invoker的时候，会找不到，从而报错）
- 基于group来实现，会更加复杂，比如提供者暴露服务的时候，要添加灰度group。 消费者消费服务的时候，要携带灰度的group

基于以上两点，进行了灰度系统2.0的改造。使用灰度IP的方式，即通过配置标明哪个应用下面的哪些机器是灰度机器，然后灰度请求则走应用下的灰度机器，正式请求则走应用下的正式机器。







## 问题



**熔断和降级在我们项目中的体现？**

- 在Dubbo框架中，服务调用错误或者超时超过一定次数，就不会再选择这个远程服务，这个是熔断的一种实现
- 在灰度系统中，当灰度服务出现问题的时候，会尝试选择正式服务来调用，保证核心业务可以正常运行。（当正式服务出现问题的时候同理）。