# 分布式事务

我们平时说的事务指的是原生事务，在单个数据库的情况下，因为有ACID特性，所以可以保证数据的一致性。

但是互联网业务数据量大，并发量大，经常使用拆库来提高系统性能，因此如果一个事务中涉及到不同的数据表，这些数据表分布在不同数据库中，这时候就不能用原生事务来保证数据的一致性了，需要使用到分布式事务。



分布式事务是指 事务的参与者、支持事务的服务器、资源服务器以及事务管理器 分别位于分布式系统的不同节点。通常一个分布式事务中会涉及对多个数据源或者业务系统的操作。



一个分布式事务可以看做由多个分布式的操作序列组成的，通常可以把这一系列分布式的操作序列看成子事务。因此，分布式事务也可以定义为一种嵌套型的事务。



## CAP理论

概念：一个分布式系统不可能同时满足 一致性、可用性、分区容错性 这三个基本需求，最多只能同时满足其中两项。

### 一致性

在分布式环境中，一致性是指**数据在多个副本之间能否保持一致的特性**。在一致性的需求下，当一个系统在数据一致性的状态下执行更新操作后，应该保证系统仍然处于一致的状态。

对于一个将数据副本分布在不同分布式节点上的操作系统来说，如果对第一个节点的数据更新操作并且更新成功后，却没有使得第二个节点上的数据得到相应的更新，于是对第二个节点的数据进行读取操作时，获取的依然是老数据（或者称为“脏数据”），这就是典型的分布式数据不一致情况。在分布式系统中，如果能够做到针对一个数据项的更新操作执行成功后，所有的用户都可以读取到其最新值，那么这样的系统就被认为具有强一致性（或者严格的一致性）。



### 可用性

可用性指 **系统提供的服务必须一直处于可用的状态，对于用户的每一个操作请求总是能够在有限的时间内返回结果。**



### 分区容错性

分区容错性指 **分布式系统在遭遇任何网络分区故障的时候，仍然需要能够保证对外提供满足一致性和可用性的服务，除非是整个网络环境发生了故障。**

**网络分区**指分布式系统中，不同的节点分布在不同的子网络（机房或者异地网络等）中，由于一些特殊的原因导致这些子网络之间出现网络不连通的情况，但各个子网络的内部网络是正常的，从而导致整个系统的网络环境被切分成若干个孤立的区域。需要注意的是，组成一个分布式系统的每个节点的加入与退出，都可以看做是一个特殊的网络分区。

对于一个分布式系统而言，分区容错性是最基本的需求。为什么这样说，原因很简单，因为既然是分布式系统，那么分布式系统中的组件必然会部署到不同节点上，因此必然出现子网络。既然出现子网络，网络问题就是一个必然会 出现的异常情况，因此必须有对应的应对策略。因此分区容错性成为了分布式系统必然面对和解决的问题。因此系统架构师往往把精力花在如何根据业务特点在C（一致性）和A（可用性）之间寻找平衡。



简单来说：CAP就是指在发生网络分区的情况下，系统可用性和一致性不能两全。因为发生了网络分区，如果系统继续提供服务，肯定会产生数据不一致。





## 2PC

在分布式系统中，每个机器节点能知道自己事务执行结果，但是无法知道其他分布式节点的事务执行结果。为了保持分布式事务的ACID特性，就需要引入一个“协调者”的角色。

协调者统一调度所有分布式节点的执行逻辑，被些被调度的分布式节点称为“参与者”。

协调者负责调度参与者的行为，并最终决定**这些参与者是否真正进行事务提交**。基于这个思想，衍生出了2PC和3PC。



2PC（two phase commit）即二阶段提交。用来保证分布式系统数据的一致性。

二阶段提交将事务的提交过程分成了两个阶段来处理。



### 阶段一：提交事务请求

- 协调者向各个参与者发送事务内容，**询问是否可以执行事务提交操作**，并开始等待各参与者的响应
- **各参与者执行事务操作**，并将undo和redo信息记入事务日志中
- 如果参与者成功执行操作，就反馈给协调者“YES”的响应，表示事务可以成功执行。否则返回NO



### 阶段二：执行事务提交

在阶段二种，协调者根据参与者的反馈情况，决定事务是否要提交。包括两种可能性

**执行事务提交**

所有参与者都回复YSE响应，则协调者开始执行事务提交

- 协调者向所有参与者发送事务提交请求
- 参与者收到commit请求后，就会执行事务提交操作，完成提交之后，会释放事务期间占用的事务资源
- 参与者完成事务提交后，向协调者反馈ACK消息
- 协调者收到所有参与者反馈的ACK消息后，完成事务

![image-20191110112657365](https://tva1.sinaimg.cn/large/006y8mN6gy1g8ss7fp6dij318o0dgwip.jpg)



**中断事务**

任何一个参与者反馈NO响应，或者等待超时后，协调者没有收到所有参与者的响应，那么就会中断事务。

- 协调者向所有参与者发送回滚请求
- 参与者执行事务回滚操作，并且释放数据库资源
- 参与者反馈回滚结果
- 协调者收到所有参与者的ACK，完成事务中断（回滚）

![image-20191110112712413](https://tva1.sinaimg.cn/large/006y8mN6gy1g8ss7nqejcj318w0ggq84.jpg)



### 优缺点



**优点**

原理简单，实现方便



**缺点**

- 同步阻塞：
  - 在2PC（二阶段提交）过程中，所有参与者处于阻塞状态，占用着数据库资源。极大限制系统性能。
- 单点问题
  - 只要协调者出现问题，整个二阶段提交就无法运转
- 数据不一致
  - 当协调者向所有参与者发送事务提交请求，由于网络或者其他原因，部分参与者没有收到commit请求，而其他参与者执行了事务提交，那么就会造成数据不一致。





## 3PC

三阶段提交又称**3PC**，其在两阶段提交的基础上**增加了CanCommit阶段**，并**引入了超时机制**。一旦事务参与者迟迟没有收到协调者的Commit请求，就会自动进行本地commit，这样相对有效地解决了协调者单点故障的问题。但是性能问题和不一致问题仍然没有根本解决。

3PC分为can commit，pre commit，do commit 三个阶段。

![image-20191110113604620](https://tva1.sinaimg.cn/large/006y8mN6gy1g8ssgvsa68j30jm0ckadb.jpg)



### 阶段一：can commit

- 协调者向所有参与者发送包含事务内容的can commit请求，询问是否可以执行事务操作，并等待各参与者的响应
- 参与者如果觉得可以成功执行事务（能够获取数据库锁），返回YES，进入预备状态；否则返回NO

![image-20191110130823161](https://tva1.sinaimg.cn/large/006y8mN6gy1g8sv4xi6bvj31om0io16h.jpg)



### 阶段二：pre commit

协调者根据参与者的响应判断是否可以进行pre commit（预提交），正常情况下，包括两种可能：

**执行事务预提交**

假设协调者从所有参与者得到的结果都是YES，就会执行事务预提交pre commit。

- 协调者向所有参与者发送pre commit请求，并进入prepared（预备）阶段
- 参与者收到pre commit请求，会执行事务操作
- 如果参与者成功执行事务，给协调者反馈ACK，并且等待最终指令（提交 或者 回滚）



**中断事务**

（针对阶段一）假如任何一个协调者向参与者返回NO，或者等待超时后，协调者没有收到全部参与者的响应，那么就会中断事务。

- 协调者向所有参与者发送abort请求（中止请求）
- 参与者中断事务



### 阶段三：do commit

在阶段二中如果所有的参与者节点都可以进行PreCommit提交，那么协调者就会从**“预提交状态”-》“提交状态”**。然后向所有的参与者节点发送**"doCommit"**请求，会存在以下两种情况：

**执行提交**

- 协调者向所有参与者发送do commit请求
- 参与者收到do commit请求，会正式进行事务提交，事务完成后释放系统资源
- 参与者完成事务提交后，向协调者反馈ACK响应
- 协调者收到所有参与者ACK后，完成事务



**中断事务**

（针对阶段二）假如任何一个协调者向参与者返回NO，或者等待超时后，协调者没有收到全部参与者的响应，那么就会中断事务。

- 协调者向所有参与者发送abort请求（中止请求）
- 参与者中断事务



**3PC相对于2PC而言到底优化了什么地方呢?**

- 2PC只有协调者才拥有超时机制，3PC对协调者和参与者都设置了超时时间
  - 如果协调者挂掉了，参与者超时之后，可以自动进行本地commit从而进行释放资源（避免锁死资源）



### 优缺点

- 优点：
  - 相对于二级段提交协议，三阶段提交协议的最大的优点就是`降低了参与者的阻塞的范围，并且能够在出现单点故障后继续达成一致`
- 缺点：
  - 三阶段提交协议在去除阻塞的同时也引入了新的问题，那就是参与者接收到precommit消息后，如果出现网络分区，此时协调者所在的节点和参与者无法进行正常的网络通信，在这种情况下，该参与者依然会进行事务的提交，这必然出现数据的不一致性。







## TCC



### 原理

TCC（**Try-Confirm-Cancel**）又称补偿事务。其核心思想是："针对每个操作都要注册一个与其对应的确认和补偿（撤销操作）"。它分为三个操作：

- Try阶段：主要是对业务系统做检测及资源预留。 

- Confirm阶段：执行业务操作。

- Cancel阶段：取消执行业务操作。



TCC事务的处理流程与2PC两阶段提交类似，不过2PC通常都是在跨库的DB层面，而TCC本质上就是一个应用层面的2PC，需要通过业务逻辑来实现。这种分布式事务的实现方式的优势在于，可以让**应用自己定义数据库操作的粒度，使得降低锁冲突、提高吞吐量成为可能**。

而不足之处则在于对应用的侵入性非常强，业务逻辑的每个分支都需要实现try、confirm、cancel三个操作。此外，其实现难度也比较大，需要按照网络状态、系统故障等不同的失败原因实现不同的回滚策略。为了满足一致性的要求，confirm和cancel接口还必须实现幂等。



TCC 分布式事务的核心思想，就是

- 先来 Try 一下，不要把业务逻辑完成。先试试看，看各个服务能不能基本正常运转，能不能先冻结我需要的资源（比如说冻结库存）。

- 如果 Try 都 OK，也就是说，底层的数据库、Redis、MQ 都是可以写入数据的，并且你保留好了需要使用的一些资源（比如冻结了一部分库存）。
- 接着，再执行各个服务的 Confirm 逻辑，也就是执行真正的事务操作，基本上 Confirm 就可以很大概率保证一个分布式事务的完成了。
- 那如果 Try 阶段某个服务就失败了，比如说底层的数据库挂了，或者 Redis 挂了，等等。比如说遇到下面这些情况时：
  - 某些资源不足了，比如说库存不够这些
  - 基础设施故障了，比如说数据库、redis、MySQL
  - 服务挂了
- 此时就自动执行各个服务的 Cancel 逻辑，**把之前的 Try 逻辑都回滚**，所有服务都不要执行任何设计的业务逻辑。保证大家要么一起成功，要么一起失败。





**如果有一些意外的情况发生了，比如说订单服务突然挂了，然后再次重启，TCC 分布式事务框架是如何保证之前没执行完的分布式事务继续执行的呢？**

所以，TCC 事务框架都是要记录一些分布式事务的活动日志的，可以在磁盘上的日志文件里记录，也可以在数据库里记录。保存下来分布式事务运行的各个阶段和状态。从而可以继续执行事务。



**万一某个服务的 Cancel 或者 Confirm 逻辑执行一直失败怎么办呢？**

TCC 事务框架会通过活动日志记录各个服务的状态。举个例子，比如发现某个服务的 Cancel 或者 Confirm 一直没成功，会不停的重试调用它的 Cancel 或者 Confirm 逻辑，务必要它成功！



**try阶段失败的时候，事务实现回滚，利用cancel方法保证事务的一致性，但是在confirm阶段，confirmA成功，confirmB成功，confirmC失败或者方法执行时间过长（也许是网络原因导致）的时候，怎么来保证事务的一致性呢?**

如果事务进行到confirm阶段失败，会让所有的参与者都执行一遍confirm操作。





### 优缺点

- 优点：
  - 性能提升：具体业务来实现控制资源，锁的粒度变小，不会锁定整个资源。
  - 数据最终一致性：基于 Confirm 和 Cancel 的幂等性，保证事务最终完成确认或者取消，保证数据的一致性。
  - 可靠性：解决了 XA 协议的协调者单点故障问题，由主业务方发起并控制整个业务活动，业务活动管理器也变成多点，引入集群。
- 缺点：
  - TCC 的 Try、Confirm 和 Cancel 操作功能要按具体业务来实现，业务耦合度较高，提高了开发成本。











## 参考

[2PC和3PC](https://www.jianshu.com/p/30a18e4ef16e)

[分布式事务](https://www.cnblogs.com/wudimanong/p/10340948.html)

[TCC原理](https://www.cnblogs.com/jajian/p/10014145.html)

[tcc-trasaction整合dubbo案例](https://blog.csdn.net/u013278314/article/details/85112891)

[5种分布式事务的解决方案和优缺点](https://mp.weixin.qq.com/s?__biz=MzI5ODQ2MzI3NQ==&mid=2247487531&idx=1&sn=b3fbc4dee7cea4a78db062a4a656afdf&chksm=eca4296fdbd3a079a8e328ec7946ced7d1f94c0f105463743a8bee569bae6da00bf2133c3e1a&mpshare=1&scene=1&srcid=&sharer_sharetime=1564287693704&sharer_shareid=136c9cdacd0d016d5845301b60ff010d&pass_ticket=RmWTghz3ejQjrtJBFtb9Nmlh2VmwJLW4ao5zaOnxURyfffs0yKiYzoIh2Uywfebh#rd)

